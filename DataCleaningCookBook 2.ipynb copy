{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \" pathname \" # defaults to you current directory\n",
    "df = pd.read_csv(data, na_values=['?']) # there are load of options here, like\\\n",
    "                        #filling na's\n",
    "df.head()\n",
    "df.shape\n",
    "df.info()\n",
    "# EXCEL ALERT!!!!: consider reviewing the data in a spreadsheet \n",
    "#first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unfamiliar with the data lineage consider shuffling it(don't forget (to remember) the random seed!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often a good idea to clean the columnames: (eg for Patsy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically removes anything that is not a letter, space or underscore.\n",
    "import string\n",
    "# the string library has default strings that contain all letters or numbers\n",
    "uppercase = string.ascii_uppercase\n",
    "lowercase = string.ascii_lowercase\n",
    "df.columns = [''.join([ch for ch in col if ch in uppercase+lowercase+' _']) \\\n",
    "              for col in df.columns]\n",
    "# for each character in each column name join characters together \n",
    "# if they are in the string \"uppercase+lowercase+' _'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace spaces in column names and convert all columns to lowercase:\n",
    "df.columns = [x.lower().replace(' ','_') for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaces spaces with underscores.\n",
    "df.columns = map(lambda x: x.replace(' ', '_'), df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of unneeded columns. Columns not needed in the analysis at hand static data AND columns that are duplicates or closely alike: e.g. 'DistanceInMiles' and 'DistanceInKilometers' (MLR doesn't like that for one:-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explicit colums to be deleted\n",
    "df.drop(['col1', 'col2'], axis =1, inplace = True)\n",
    "#or redefine df with the columns you want\n",
    "df = df[['col3', 'col4']] #!! [[]] !! not ([])\n",
    "#rename FIRST if your need to retain the old one\n",
    "df2 = df[['col3', 'col4']]\n",
    "#Creativity is also possible\n",
    "df = [[col for col in df.columns if 'keyword' in col\\\n",
    "       and 'keyword' not in col]] #!![[]]!!\n",
    "List = [col for col in df.columns if 'keyword' in col\\\n",
    "       and 'keyword' not in col]# single []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May be a good time to combine/convert columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['colNEW'] = df['col1'] + df['col2'] / df['col3']\n",
    "df['colNEW'] = 10\n",
    "df['colNEW'] = np.mean(df['col1'])\n",
    "df['colNEW'] =df['col1'] / 2,52 # inches to centimeters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the colums data types make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "#convert to ints to floats\n",
    "df.['col1'] = df.['col1'].astype(np.float64) #or something else\n",
    "# to string?\n",
    "df.['col2'] = df.['col2'].astype(np.str)\n",
    "#BTW\n",
    "df.[['col1','col2']] = df.[['col1','col2']].astype(np.str) #also works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically however columns show a 'object' where you expect a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col1'].unique() #will likely indicate problems\n",
    "df.['col1'].value_counts # also does the trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function looping over values for correction and type settting\n",
    "def cleaner(x):\n",
    "    x = x.replace('-','') #replace something at the same time\n",
    "    try:\n",
    "        return float(x) #forces float\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "df['col1']= df['col1'].map(cleaner)\n",
    "# df = df.apply(cleaner) will do the WHOLE data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or:\n",
    "df['col1'] = df['col1'].map(lambda x: float(x))\n",
    "#or\n",
    "df.loc[:,'col1'] = df['col1'].map(lambda x: 1 if x == 'yes' else 0 if x == 'no' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get into the difficult bit: 'Real' cleaning, namely Na/Null, outliers (including inconsistencies: e.g. a 3 year old owning a car) Consider: Size of the data set, use of the data, the purpose of the analysis. Scan the 'cleaned' data for patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial EDA\n",
    "from pandas_summary import DataFrameSummary\n",
    "dfs = DataFrameSummary(df)\n",
    "dfs.columns_stats # select suspect columns\n",
    "dfs.summary() # inspect the suspects\n",
    "dfs['col1'] # detail the suspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.select_dtypes(include=['int64'])\n",
    "y = x.describe()\n",
    "y.to_csv('out.csv')\n",
    "y.to_excel('out.xls') # EXCEL ALERT!!! :-(((\n",
    "\n",
    "# 'int', 'float', object, 'datetime'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Or create a standardised box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the numerical columns\n",
    "df_num = df.select_dtypes(exclude=['object'])\n",
    "df_stand = (df - df.np.mean()) / df.np.std()\n",
    "#draw the plot\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax = fig.gca()\n",
    "\n",
    "ax = sns.boxplot(data=df_STAND, orient='h', fliersize=5, \n",
    "                 linewidth=1, notch=True, saturation=0.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Na's\n",
    "from numpy import nan as NA\n",
    "df.dropna() #returns rows with any NA\n",
    "df = df.dropna() #removes rows with any NA\n",
    "df = df.dropna(how = 'all') #removes rows with only NA's\n",
    "#the more gentle way:\n",
    "# This will show us records where `df['col1']` is null.\n",
    "mask = df['col1'].isnull()\n",
    "# use the mask to remove those values\n",
    "df = df.loc[~mask,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data entry errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask:\n",
    "mask = df['col1'] == value # <>== etc\n",
    "mask1 = (df['col1']) > value) & (df['col2'] < value)\n",
    "# view rows\n",
    "df.loc[mask,:]\n",
    "#or:\n",
    "df.loc[df['col1'] == value]\n",
    "#decide what to do: override the culprit:\n",
    "df.loc[mask, 'col1'] = np.nan #or override the value\n",
    "df.loc[mask, 'col1'] = new_value/new string\n",
    "#or delete entire row\n",
    "df = df.loc[~mask,:].reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating rows with outliers in 1 column based on percentile\n",
    "https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.percentile(df['col1'], [5, 95])\n",
    "df = df[(df['col1'] > P[0]) & (df['col1'] < P[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on Mean +/- 3 * std of a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready ?  Save the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('filename.pkl')\n",
    "df = pd.read_pickle('filename.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a kitkat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print all rows with some defined characterisics\n",
    "# in a df, for inspection\n",
    "# def row_inspector(row):\n",
    "def row_inspector(row):\n",
    "    print ('--------------------------------')\n",
    "    print(row['col1'], row['col2'],row['col3'],\\\n",
    "         'MyComment', row['col3']' < condition)\n",
    "#row_inspector(df.iloc[0,:]) test\n",
    "df.head(X).apply(row_inspector, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIP: knn-classification-imputation-solutions\n",
    "# filling blanks with nearest neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing field int bianvy using lambda\n",
    "y = df['Result'].map(lambda x: 1 if x == 'Play' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.Category == 'ASSUALT' \n",
    "df.loc[mask, ['Category']] = 'ASSAULT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signs that do not seem to be wanted to be deleted \n",
    "df[col] = df[col].astype(str)  # cast to string\n",
    "\n",
    "# all the string surgery goes in here\n",
    "df[col] = df[col].replace('$', '')\n",
    "df[col] = df[col].replace(',', '')  # assuming ',' is the thousand's separator in your locale\n",
    "df[col] = df[col].replace('%', '')\n",
    "\n",
    "df[col] = df[col].astype(float)  # cast back to appropriate type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
