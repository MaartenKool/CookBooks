{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "directory = '/Users/maarten/Documents/git/CookBooks/Sources/'\n",
    "file_list = glob.glob(directory + 'pos/'+'*.txt')\n",
    "\n",
    "# create document list:\n",
    "corpus = []\n",
    "for filename in file_list[:10]:\n",
    "    with open(filename, 'r') as f:\n",
    "        corpus.append(f.read()) # option 1, to get a direct string\n",
    "        # documents.append(f.readlines()) # option 2, to get a list of lines\n",
    "        # documents.append([item.strip() for item in f.readlines()]) # option 3, to get a list of lines with no linefeeds\n",
    "        # documents.append(f.read().replace('\\n', ' ') # option 4, to get a direct string, linefeeds replaced with spaces\n",
    "   \n",
    "#data from http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "#https://stackoverflow.com/questions/30114934/python-how-to-read-a-directory-of-texts-into-a-list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =  pd.DataFrame(columns=['review', 'label'])\n",
    "df['review'] = corpus\n",
    "df['label'] = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "directory = '/Users/maarten/Documents/git/CookBooks/Sources/'\n",
    "file_list = glob.glob(directory + 'neg/'+'*.txt')\n",
    "\n",
    "# create document list:\n",
    "corpus_ = []\n",
    "for filename in file_list[:10]:\n",
    "    with open(filename, 'r') as f:\n",
    "        corpus_.append(f.read()) # option 1, to get a direct string\n",
    "        # documents.append(f.readlines()) # option 2, to get a list of lines\n",
    "        # documents.append([item.strip() for item in f.readlines()]) # option 3, to get a list of lines with no linefeeds\n",
    "        # documents.append(f.read().replace('\\n', ' ') # option 4, to get a direct string, linefeeds replaced with spaces\n",
    "   \n",
    "#https://stackoverflow.com/questions/30114934/python-how-to-read-a-directory-of-texts-into-a-list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ =  pd.DataFrame(columns=['review', 'label'])\n",
    "df_['review'] = corpus\n",
    "df_['label'] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df_, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I saw the movie with two grown children. Altho...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You're using the IMDb.&lt;br /&gt;&lt;br /&gt;You've given...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This was a good film with a powerful message o...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Made after QUARTET was, TRIO continued the qua...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For a mature man, to admit that he shed a tear...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I saw the movie with two grown children. Altho...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>You're using the IMDb.&lt;br /&gt;&lt;br /&gt;You've given...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This was a good film with a powerful message o...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Made after QUARTET was, TRIO continued the qua...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>For a mature man, to admit that he shed a tear...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I saw the movie with two grown children. Altho...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>You're using the IMDb.&lt;br /&gt;&lt;br /&gt;You've given...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>This was a good film with a powerful message o...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Made after QUARTET was, TRIO continued the qua...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>For a mature man, to admit that he shed a tear...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review label\n",
       "0   For a movie that gets no respect there sure ar...   pos\n",
       "1   Bizarre horror movie filled with famous faces ...   pos\n",
       "2   A solid, if unremarkable film. Matthau, as Ein...   pos\n",
       "3   It's a strange feeling to sit alone in a theat...   pos\n",
       "4   You probably all already know this by now, but...   pos\n",
       "5   I saw the movie with two grown children. Altho...   pos\n",
       "6   You're using the IMDb.<br /><br />You've given...   pos\n",
       "7   This was a good film with a powerful message o...   pos\n",
       "8   Made after QUARTET was, TRIO continued the qua...   pos\n",
       "9   For a mature man, to admit that he shed a tear...   pos\n",
       "10  For a movie that gets no respect there sure ar...   neg\n",
       "11  Bizarre horror movie filled with famous faces ...   neg\n",
       "12  A solid, if unremarkable film. Matthau, as Ein...   neg\n",
       "13  It's a strange feeling to sit alone in a theat...   neg\n",
       "14  You probably all already know this by now, but...   neg\n",
       "15  I saw the movie with two grown children. Altho...   neg\n",
       "16  You're using the IMDb.<br /><br />You've given...   neg\n",
       "17  This was a good film with a powerful message o...   neg\n",
       "18  Made after QUARTET was, TRIO continued the qua...   neg\n",
       "19  For a mature man, to admit that he shed a tear...   neg\n",
       "20  For a movie that gets no respect there sure ar...   neg\n",
       "21  Bizarre horror movie filled with famous faces ...   neg\n",
       "22  A solid, if unremarkable film. Matthau, as Ein...   neg\n",
       "23  It's a strange feeling to sit alone in a theat...   neg\n",
       "24  You probably all already know this by now, but...   neg\n",
       "25  I saw the movie with two grown children. Altho...   neg\n",
       "26  You're using the IMDb.<br /><br />You've given...   neg\n",
       "27  This was a good film with a powerful message o...   neg\n",
       "28  Made after QUARTET was, TRIO continued the qua...   neg\n",
       "29  For a mature man, to admit that he shed a tear...   neg"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['review'].values\n",
    "y = df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,) (10,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-4b14b86c927d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mreview_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,) (10,) "
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(1999)\n",
    "# tf.random.set_seed(1999)\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "review_corpus = X_train + X_test\n",
    "\n",
    "tokenizer.fit_on_texts(review_corpus)\n",
    "\n",
    "#this transforms the texts in to sequences of indices (aka transformer)\n",
    "encoded_review_corpus = tokenizer.texts_to_sequences(review_corpus)\n",
    "\n",
    "#Retrieve Vocab size from corpus\n",
    "vocab_size=len(tokenizer.word_index)+1 #allow for '0' for padding\n",
    "# print(f'#unique words == vocab_size {len(tokenizer.word_index}')\n",
    "# print(encoded_review_corpus)\n",
    "\n",
    "# # Determine longest sentence to determine padding\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# word_count = lambda sentence: len(word_tokenize(sentence)) #can recognize punctuation\n",
    "# # word_count = lambda sentence: len(sentence.split(' ')) # does NOT recognize punctuation\n",
    "# longest_sentence = max(docs, key=word_count)\n",
    "# length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "# print(f'length_long_sentence {length_long_sentence}')\n",
    "# max_length = length_long_sentence\n",
    "\n",
    "# # Padding of the docs\n",
    "# padded_docs2 = pad_sequences(encoded_docs2, maxlen=max_length, padding='post')\n",
    "# print(padded_docs2)\n",
    "\n",
    "# # define the model\n",
    "# model2 = Sequential()\n",
    "# model2.add(keras.layers.Embedding(vocab_size, 8, input_length=max_length))\n",
    "# model2.add(Flatten()) #comment out en using GlobalMaxPool1D layer)\n",
    "# # model2.add(keras.layers.GlobalMaxPool1D())\n",
    "# model2.add(Dense(1, activation='sigmoid')) # <== binary, adjust for number of classes\n",
    "\n",
    "# # compile the model\n",
    "# model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # summarize the model\n",
    "# print(model2.summary())\n",
    "\n",
    "# # fit the model\n",
    "# model2.fit(padded_docs2, labels, epochs=50, verbose=0)\n",
    "\n",
    "# # evaluate the model\n",
    "# loss, accuracy = model2.evaluate(padded_docs2, labels, verbose=0)\n",
    "# print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['tinker', 'tailor', 'soldier', 'spy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.asarray(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['tinker'],\n",
       "       ['tailor'],\n",
       "       ['soldier'],\n",
       "       ['spy']], dtype='<U7')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [['tinker', 'tailor'], ['soldier', 'spy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tinker', 'tailor']\n",
      "['soldier', 'spy']\n"
     ]
    }
   ],
   "source": [
    "for i in corpus:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinker\n",
      "tailor\n",
      "soldier\n",
      "spy\n"
     ]
    }
   ],
   "source": [
    "for book in corpus:\n",
    "    for y in book:\n",
    "        print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.asarray(corpus)#.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tinker', 'tailor', 'soldier', 'spy']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ravel().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[['a','b','c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
