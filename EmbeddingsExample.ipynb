{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Embeddings\" data-toc-modified-id=\"Embeddings-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Embeddings</a></span><ul class=\"toc-item\"><li><span><a href=\"#PCA-illustration-of-getting-embeddings\" data-toc-modified-id=\"PCA-illustration-of-getting-embeddings-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>PCA illustration of getting embeddings</a></span></li><li><span><a href=\"#Supervised-example\" data-toc-modified-id=\"Supervised-example-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Supervised example</a></span></li><li><span><a href=\"#Word-embeddings\" data-toc-modified-id=\"Word-embeddings-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Word embeddings</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Skip-gram-predicts-surrounding-words-given-the-current-word.\" data-toc-modified-id=\"Skip-gram-predicts-surrounding-words-given-the-current-word.-1.3.0.1\"><span class=\"toc-item-num\">1.3.0.1&nbsp;&nbsp;</span>Skip-gram predicts surrounding words given the current word.</a></span></li><li><span><a href=\"#CBOW-predicts-next-word-given-surronding-words.\" data-toc-modified-id=\"CBOW-predicts-next-word-given-surronding-words.-1.3.0.2\"><span class=\"toc-item-num\">1.3.0.2&nbsp;&nbsp;</span>CBOW predicts next word given surronding words.</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "*In this context* an embedding is a numerical representation of non-numerical data. The purpose is primarily for mathematical convenience i.e. it enables computations to may be made. For example: One Hot encoder encodes a categorical variable with 6 possible values for its value '3' to 0 0 1 0 0 0. In real life this may mean hair color 'blond'. For the complete picture:\n",
    "\n",
    "Color  |  encoding\n",
    ":--- |:--- |\n",
    "Black | 1 0 0 0 0\n",
    "Fair | 0 1 0 0 0\n",
    "Blonde | 0 0 1 0 0\n",
    "Red | 0 0 0 1 0\n",
    "Gray | 0 0 0 0 1\n",
    "None | 0 0 0 0 0\n",
    "\n",
    "In traditional ML one hot encoding worked fine for most cases. However with the appearance of 'Big Data'some problems arose:  \n",
    "    - The number of categories can be huge. E.g. consider the number of titles in the IMDB move database\n",
    "    - The number of observations can be enormous\n",
    "IN this 'Big Data' environment One-hot encoding results in extremely sparse matrices which any, machine or deep, learning algorithm  has problems dealing with.\n",
    "\n",
    "Traditionally PCA would be applied to reduce the number of dimensions. But the disadvantage is that a inverse of the matrix is needed. For enormous data sets this actually a memory/computational problem: Enter Embeddings/embedding layers.\n",
    "\n",
    "Embedding is in that sense a dimensionality reduction technique to make large categorical data points computationally manageable. There are 2 types of reduction:\n",
    "\n",
    "1. 'Unsupervised' in the sense that it takes the features at face-value \n",
    "PCA could serve as an example from the ML world. PCA tries to minimize the variation \n",
    "2. 'Supervised' in the sense it learns from a 'target'\n",
    "LDA (Linear Discriminant Analysis) is an example. It tries to maximize the separation of known categories \n",
    "\n",
    "Since Bayes we know that the use of prior information will lead to better predictions. Therefore a 'supervised' embedding is preferred if possible if the target is known.\n",
    "\n",
    "When to use embeddings rather than One_hot?\n",
    "\n",
    "It depends on the number of categories:\n",
    "\n",
    "General rules of thumb:\n",
    "\n",
    "Under 10 : one hot\n",
    "10-50: use formula embedding_size = min(50, NumberOfCats+1/2)\n",
    "ove 50: 50 max.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA illustration of getting embeddings\n",
    "\n",
    "Purely to illustrate what goes on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "import pandas as pd\n",
    "\n",
    "#create categories\n",
    "haircolor = ['black', 'blond', 'fair', 'red', 'grey', 'none', 'marron']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#create data\n",
    "se = []\n",
    "for i in range(100):\n",
    "    se.append(choice(haircolor))\n",
    "df['haircolor'] = se \n",
    "\n",
    "#get the One hot\n",
    "df_ = pd.get_dummies(df[['haircolor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   haircolor\n",
       "41       red\n",
       "93     black\n",
       "30       red\n",
       "80     blond\n",
       "26      fair\n",
       "12      grey\n",
       "96      grey\n",
       "89     blond\n",
       "63      grey\n",
       "9     marron"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haircolor_black</th>\n",
       "      <th>haircolor_blond</th>\n",
       "      <th>haircolor_fair</th>\n",
       "      <th>haircolor_grey</th>\n",
       "      <th>haircolor_marron</th>\n",
       "      <th>haircolor_none</th>\n",
       "      <th>haircolor_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    haircolor_black  haircolor_blond  haircolor_fair  haircolor_grey  \\\n",
       "41                0                0               0               0   \n",
       "93                1                0               0               0   \n",
       "30                0                0               0               0   \n",
       "80                0                1               0               0   \n",
       "26                0                0               1               0   \n",
       "12                0                0               0               1   \n",
       "96                0                0               0               1   \n",
       "89                0                1               0               0   \n",
       "63                0                0               0               1   \n",
       "9                 0                0               0               0   \n",
       "\n",
       "    haircolor_marron  haircolor_none  haircolor_red  \n",
       "41                 0               0              1  \n",
       "93                 0               0              0  \n",
       "30                 0               0              1  \n",
       "80                 0               0              0  \n",
       "26                 0               0              0  \n",
       "12                 0               0              0  \n",
       "96                 0               0              0  \n",
       "89                 0               0              0  \n",
       "63                 0               0              0  \n",
       "9                  1               0              0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.sample(10, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#pca \n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca.fit(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.096952</td>\n",
       "      <td>-0.086958</td>\n",
       "      <td>-0.108315</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.096952</td>\n",
       "      <td>-0.086958</td>\n",
       "      <td>-0.108315</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.130854</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.081798</td>\n",
       "      <td>-0.068073</td>\n",
       "      <td>-0.078232</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.130854</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.218256</td>\n",
       "      <td>-0.518452</td>\n",
       "      <td>0.705315</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2 haircolor\n",
       "41 -0.096952 -0.086958 -0.108315       red\n",
       "93 -0.154020 -0.195346 -0.468987     black\n",
       "30 -0.096952 -0.086958 -0.108315       red\n",
       "80  0.868897  0.130854  0.082864     blond\n",
       "26 -0.081798 -0.068073 -0.078232      fair\n",
       "12 -0.154020 -0.195346 -0.468987      grey\n",
       "96 -0.154020 -0.195346 -0.468987      grey\n",
       "89  0.868897  0.130854  0.082864     blond\n",
       "63 -0.154020 -0.195346 -0.468987      grey\n",
       "9  -0.218256 -0.518452  0.705315    marron"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df__ = pd.DataFrame(pca.transform(df_))\n",
    "df__['haircolor'] = df['haircolor']\n",
    "df__.sample(10,random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.218256</td>\n",
       "      <td>-0.518452</td>\n",
       "      <td>0.705315</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081798</td>\n",
       "      <td>-0.068073</td>\n",
       "      <td>-0.078232</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.130854</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.096952</td>\n",
       "      <td>-0.086958</td>\n",
       "      <td>-0.108315</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.374408</td>\n",
       "      <td>0.792713</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2 haircolor\n",
       "0  -0.218256 -0.518452  0.705315    marron\n",
       "1  -0.081798 -0.068073 -0.078232      fair\n",
       "2   0.868897  0.130854  0.082864     blond\n",
       "3  -0.154020 -0.195346 -0.468987      grey\n",
       "4  -0.154020 -0.195346 -0.468987     black\n",
       "5  -0.096952 -0.086958 -0.108315       red\n",
       "11 -0.374408  0.792713  0.201294      none"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df__.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised example\n",
    "\n",
    "**Just illustrating the mechanics** \n",
    "\n",
    "Suppose this s part of marketing survey to see how likely people are to buy suntan lotion.\n",
    "\n",
    "If possible supervised embedding is preferred over unsupervised, but only if it makes sense. I.e. there is a relationship between the 2 variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create categorical target with 5 values\n",
    "df_['buy_suntan?'] = 'likely'\n",
    "\n",
    "df_.loc[(df_['haircolor_black'] == 1) | (df_['haircolor_marron'] == 1), 'buy_suntan?'] = 'unlikely'\n",
    "df_.loc[(df_['haircolor_grey'] == 1), 'buy_suntan?'] = 'possible'\n",
    "df_.loc[(df_['haircolor_none'] == 1), 'buy_suntan?'] = 'undetermined'\n",
    "df_.loc[(df_['haircolor_red'] == 1), 'buy_suntan?'] = 'very likely'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haircolor_black</th>\n",
       "      <th>haircolor_blond</th>\n",
       "      <th>haircolor_fair</th>\n",
       "      <th>haircolor_grey</th>\n",
       "      <th>haircolor_marron</th>\n",
       "      <th>haircolor_none</th>\n",
       "      <th>haircolor_red</th>\n",
       "      <th>buy_suntan?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>very likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unlikely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>very likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unlikely</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    haircolor_black  haircolor_blond  haircolor_fair  haircolor_grey  \\\n",
       "41                0                0               0               0   \n",
       "93                1                0               0               0   \n",
       "30                0                0               0               0   \n",
       "80                0                1               0               0   \n",
       "26                0                0               1               0   \n",
       "12                0                0               0               1   \n",
       "96                0                0               0               1   \n",
       "89                0                1               0               0   \n",
       "63                0                0               0               1   \n",
       "9                 0                0               0               0   \n",
       "\n",
       "    haircolor_marron  haircolor_none  haircolor_red  buy_suntan?  \n",
       "41                 0               0              1  very likely  \n",
       "93                 0               0              0     unlikely  \n",
       "30                 0               0              1  very likely  \n",
       "80                 0               0              0       likely  \n",
       "26                 0               0              0       likely  \n",
       "12                 0               0              0     possible  \n",
       "96                 0               0              0     possible  \n",
       "89                 0               0              0       likely  \n",
       "63                 0               0              0     possible  \n",
       "9                  1               0              0     unlikely  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.sample(10, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_[['haircolor_black', 'haircolor_blond', 'haircolor_fair',\n",
    "       'haircolor_grey', 'haircolor_marron', 'haircolor_none', 'haircolor_red']]\n",
    "y = df_['buy_suntan?']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embed_1</th>\n",
       "      <th>Embed_2</th>\n",
       "      <th>Embed_3</th>\n",
       "      <th>buy_suntan?</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.560238</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.560238</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.560238</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-3.439762</td>\n",
       "      <td>1.698548e+15</td>\n",
       "      <td>-5.316717e+15</td>\n",
       "      <td>possible</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.560238</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-3.439762</td>\n",
       "      <td>1.698548e+15</td>\n",
       "      <td>-5.316717e+15</td>\n",
       "      <td>possible</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.560238</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.560238</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.560238</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.560238</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Embed_1       Embed_2       Embed_3 buy_suntan? haircolor\n",
       "14  0.560238  2.585153e+15  1.403831e+15    unlikely    marron\n",
       "80  0.560238  2.585153e+15  1.403831e+15      likely     blond\n",
       "84  0.560238  2.585153e+15  1.403831e+15      likely      fair\n",
       "35 -3.439762  1.698548e+15 -5.316717e+15    possible      grey\n",
       "47  0.560238  2.585153e+15  1.403831e+15    unlikely     black\n",
       "63 -3.439762  1.698548e+15 -5.316717e+15    possible      grey\n",
       "65  0.560238  2.585153e+15  1.403831e+15    unlikely     black\n",
       "10  0.560238  2.585153e+15  1.403831e+15      likely     blond\n",
       "44  0.560238  2.585153e+15  1.403831e+15      likely     blond\n",
       "67  0.560238  2.585153e+15  1.403831e+15    unlikely    marron"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=3)\n",
    "ldX = pd.DataFrame(lda.fit(X,y).transform(X), columns=['Embed_1', 'Embed_2', 'Embed_3' ])\n",
    "ldX['buy_suntan?'] = df_['buy_suntan?']\n",
    "ldX['haircolor'] = df['haircolor']\n",
    "ldX.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there are 5 unique embeddings, not 7. This reflects the grouping that was coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embed_1</th>\n",
       "      <th>Embed_2</th>\n",
       "      <th>Embed_3</th>\n",
       "      <th>buy_suntan?</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.602384e-01</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.602384e-01</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.602384e-01</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.439762e+00</td>\n",
       "      <td>1.698548e+15</td>\n",
       "      <td>-5.316717e+15</td>\n",
       "      <td>possible</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.602384e-01</td>\n",
       "      <td>2.585153e+15</td>\n",
       "      <td>1.403831e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.496286e+16</td>\n",
       "      <td>-5.559168e+15</td>\n",
       "      <td>3.086866e+14</td>\n",
       "      <td>very likely</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.496286e+16</td>\n",
       "      <td>-5.559168e+15</td>\n",
       "      <td>3.086866e+14</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Embed_1       Embed_2       Embed_3   buy_suntan? haircolor\n",
       "0   5.602384e-01  2.585153e+15  1.403831e+15      unlikely    marron\n",
       "1   5.602384e-01  2.585153e+15  1.403831e+15        likely      fair\n",
       "2   5.602384e-01  2.585153e+15  1.403831e+15        likely     blond\n",
       "3  -3.439762e+00  1.698548e+15 -5.316717e+15      possible      grey\n",
       "4   5.602384e-01  2.585153e+15  1.403831e+15      unlikely     black\n",
       "5  -1.496286e+16 -5.559168e+15  3.086866e+14   very likely       red\n",
       "11  1.496286e+16 -5.559168e+15  3.086866e+14  undetermined      none"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldX.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "\n",
    "In very simplistic terms, Word Embeddings are the texts converted into numbers and there may be different numerical representations of the same text.\n",
    "\n",
    "Different types of Word Embeddings:\n",
    "\n",
    "1. Frequency based Embedding\n",
    "    1. Count Vectors\n",
    "    - TF-IDF\n",
    "    - Co-Occurrence Matrix\n",
    "\n",
    "2. Prediction based Embedding\n",
    "    1. CBOW\n",
    "    - Skip-Gram\n",
    "    \n",
    "Uncomplicate:\n",
    "    - embedding\n",
    "    - algo\n",
    "    - implementation in \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skip-gram predicts surrounding words given the current word.\n",
    "##### CBOW predicts next word given surronding words.\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Word2Vec-Training-Models.png\" />\n",
    "https://hackernoon.com/hn-images/1*TTPHUemZjeOjALy9k3KX2w.png\n",
    "<img src=\"https://hackernoon.com/hn-images/1*d47v_FGYKsNT_QRpCNZlfA.png\" />\n",
    "#https://hackernoon.com/hn-images/1*d47v_FGYKsNT_QRpCNZlfA.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1031 15:25:22.694109 54764 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1031 15:25:22.718116 54764 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1031 15:25:22.724121 54764 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1031 15:25:22.784113 54764 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1031 15:25:22.820153 54764 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1031 15:25:22.829113 54764 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17, 8], [49, 49], [18, 5], [39, 49], [31], [36], [32, 5], [23, 49], [32, 49], [35, 11, 8, 40]]\n",
      "[[17  8  0  0]\n",
      " [49 49  0  0]\n",
      " [18  5  0  0]\n",
      " [39 49  0  0]\n",
      " [31  0  0  0]\n",
      " [36  0  0  0]\n",
      " [32  5  0  0]\n",
      " [23 49  0  0]\n",
      " [32 49  0  0]\n",
      " [35 11  8 40]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 15:25:23.153116 54764 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 8],\n",
       " [49, 49],\n",
       " [18, 5],\n",
       " [39, 49],\n",
       " [31],\n",
       " [36],\n",
       " [32, 5],\n",
       " [23, 49],\n",
       " [32, 49],\n",
       " [35, 11, 8, 40]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = open('FinKwijt\\glove.6B.100d.txt', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_io.TextIOWrapper' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d8a9ea859afd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglove_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for i in glove_file[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at row 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f715af44761b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nrows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1995\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1996\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 8"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(glove_file, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='FinKwijt\\\\\\\\glove.6B.100d.txt' mode='r' encoding='utf8'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the -0.038194 -0.24487 0.72812 -0.39961 0.0831...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>, -0.10767 0.11053 0.59812 -0.54361 0.67396 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. -0.33979 0.20941 0.46348 -0.64792 -0.38377 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of -0.1529 -0.24279 0.89837 0.16996 0.53516 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to -0.1897 0.050024 0.19084 -0.049184 -0.08973...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  the -0.038194 -0.24487 0.72812 -0.39961 0.0831...\n",
       "1  , -0.10767 0.11053 0.59812 -0.54361 0.67396 0....\n",
       "2  . -0.33979 0.20941 0.46348 -0.64792 -0.38377 0...\n",
       "3  of -0.1529 -0.24279 0.89837 0.16996 0.53516 0....\n",
       "4  to -0.1897 0.050024 0.19084 -0.049184 -0.08973..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/linear-discriminant-analysis-in-python-76b8b17817c2\n",
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = pd.Categorical.from_codes(wine.target, wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[class_0, class_0, class_0, class_0, class_0, ..., class_2, class_2, class_2, class_2, class_2]\n",
       "Length: 178\n",
       "Categories (3, object): [class_0, class_1, class_2]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "X_lda = lda.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument must be a mpl color, a sequence of mpl colors or a sequence of numbers, not [class_0, class_0, class_0, class_0, class_0, ..., class_2, class_2, class_2, class_2, class_2]\nLength: 178\nCategories (3, object): [class_0, class_1, class_2].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[0;32m   4276\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Then is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4277\u001b[1;33m                 \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4278\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;31m# tuple color.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid RGBA argument: 'class_0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-66734cca10dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rainbow'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0medgecolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2839\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2840\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[1;32m-> 2841\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2842\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4444\u001b[0m             self._parse_scatter_color_args(\n\u001b[0;32m   4445\u001b[0m                 \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4446\u001b[1;33m                 get_next_color_func=self._get_patches_for_fill.get_next_color)\n\u001b[0m\u001b[0;32m   4447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mplotnonfinite\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[0;32m   4296\u001b[0m                         \u001b[1;34m\"'c' argument must be a mpl color, a sequence of mpl \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4297\u001b[0m                         \u001b[1;34m\"colors or a sequence of numbers, not {}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4298\u001b[1;33m                             \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# note: could be long depending on c\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4299\u001b[0m                     )\n\u001b[0;32m   4300\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'c' argument must be a mpl color, a sequence of mpl colors or a sequence of numbers, not [class_0, class_0, class_0, class_0, class_0, ..., class_2, class_2, class_2, class_2, class_2]\nLength: 178\nCategories (3, object): [class_0, class_1, class_2]."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.scatter(\n",
    "    X_lda[:,0],\n",
    "    X_lda[:,1],\n",
    "    c=y,\n",
    "    cmap='rainbow',\n",
    "    alpha=0.7,\n",
    "    edgecolors='b'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9912])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load the Iris flower dataset:\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create an LDA that will reduce the data down to 1 feature\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "# run an LDA and use it to transform the features\n",
    "X_lda = lda.fit(X, y).transform(X)\n",
    "\n",
    "# Print the number of features\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_lda.shape[1])\n",
    "\n",
    "## View the ratio of explained variance\n",
    "lda.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 54\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "# Load libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the data\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Standardize the feature matrix\n",
    "X = StandardScaler().fit_transform(digits.data)\n",
    "y =  digits.target\n",
    "# Create a PCA that will retain 99% of the variance\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "\n",
    "# Conduct PCA\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Show results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 9\n",
      "[0.2891 0.1826 0.1696 0.1167 0.083  0.0657 0.0431 0.0293 0.0208]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(64, 10 - 1) = 9 components.\n",
      "  ChangedBehaviorWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=54)\n",
    "\n",
    "# run an LDA and use it to transform the features\n",
    "X_lda = lda.fit(X, y).transform(X)\n",
    "\n",
    "# Print the number of features\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_lda.shape[1])\n",
    "\n",
    "## View the ratio of explained variance\n",
    "print(lda.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lda.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.drop('buy_suntan?', axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(df_.drop('buy_suntan?', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Python 3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn 0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow 2.0-preview is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(100, 1, input_length=7))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(3))#, activation='sigmoid'))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be\n",
    "# no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "input_array = np.asarray(df_.drop('buy_suntan?', axis=1))#np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "# assert output_array.shape == (32, 10, 64)\n",
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(3, input_shape=input_array.shape[1:])#,\n",
    "#     keras.layers.Dense(3)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('rmsprop', 'mse')\n",
    "output_array_ = model.predict(input_array)\n",
    "# assert output_array.shape == (32, 10, 64)\n",
    "output_array_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>hair_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710024</td>\n",
       "      <td>-0.748557</td>\n",
       "      <td>-0.285666</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.436497</td>\n",
       "      <td>0.294690</td>\n",
       "      <td>0.325131</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.586755</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.191005</td>\n",
       "      <td>0.753687</td>\n",
       "      <td>-0.585121</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.454533</td>\n",
       "      <td>0.574956</td>\n",
       "      <td>-0.742604</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.596687</td>\n",
       "      <td>-0.258554</td>\n",
       "      <td>-0.447850</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.526522</td>\n",
       "      <td>0.332875</td>\n",
       "      <td>0.448169</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2 hair_color\n",
       "0   0.710024 -0.748557 -0.285666      black\n",
       "1  -0.436497  0.294690  0.325131       none\n",
       "2   0.586755 -0.025443  0.317029        red\n",
       "8   0.191005  0.753687 -0.585121       grey\n",
       "9  -0.454533  0.574956 -0.742604     marron\n",
       "11 -0.596687 -0.258554 -0.447850       fair\n",
       "12 -0.526522  0.332875  0.448169      blond"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = pd.DataFrame(output_array_)#.drop_duplicates()\n",
    "dfx['hair_color'] = df['haircolor']\n",
    "dfx.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.218256</td>\n",
       "      <td>-0.518452</td>\n",
       "      <td>0.705315</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081798</td>\n",
       "      <td>-0.068073</td>\n",
       "      <td>-0.078232</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.130854</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.096952</td>\n",
       "      <td>-0.086958</td>\n",
       "      <td>-0.108315</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.374408</td>\n",
       "      <td>0.792713</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2 haircolor\n",
       "0  -0.218256 -0.518452  0.705315    marron\n",
       "1  -0.081798 -0.068073 -0.078232      fair\n",
       "2   0.868897  0.130854  0.082864     blond\n",
       "3  -0.154020 -0.195346 -0.468987      grey\n",
       "4  -0.154020 -0.195346 -0.468987     black\n",
       "5  -0.096952 -0.086958 -0.108315       red\n",
       "11 -0.374408  0.792713  0.201294      none"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: tf.Tensor(\n[[0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0.]], shape=(2, 7), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-687d5118e10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m model = keras.models.Sequential([\n\u001b[0;32m----> 7\u001b[0;31m     keras.backend.one_hot((100,1), 7)])#,\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#     keras.layers.Dense(3)])#,#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    156\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    157\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: tf.Tensor(\n[[0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0.]], shape=(2, 7), dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.backend.one_hot((100,1), 7)])#,\n",
    "#     keras.layers.Dense(3)])#,#\n",
    "\n",
    "\n",
    "input_array = np.asarray(df)#np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.random.randint(1000, size=(32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(1000, 64, input_length=10))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be\n",
    "# no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143, 608, 200, 123, 186, 325, 463, 348, 770, 659],\n",
       "       [763, 954, 931, 402, 345, 962, 510, 146, 147, 863],\n",
       "       [710, 819, 488, 928, 935, 639, 550, 337, 871, 640],\n",
       "       [778, 987, 952, 472, 945, 150, 414, 989, 297, 610],\n",
       "       [262, 763, 143, 345, 623, 571, 880,   1, 896, 303],\n",
       "       [253, 651, 452,  36, 159,   8, 232,  98, 658, 815],\n",
       "       [207, 130, 403, 151,  53, 119, 672, 919, 627, 586],\n",
       "       [624, 967, 419, 421, 103, 851, 253, 226, 111, 509],\n",
       "       [472,  98, 152, 860, 913, 895, 877, 337, 705, 821],\n",
       "       [162, 719, 956, 680, 995, 160, 579, 800, 397, 276],\n",
       "       [815, 915, 503, 895, 391, 134, 194, 400, 639,  32],\n",
       "       [687, 459, 954, 882, 469, 374,  21, 749, 669,  37],\n",
       "       [229, 364, 562, 437, 775, 282,  26, 225, 276, 797],\n",
       "       [608, 283, 878, 959, 480, 452, 828, 815, 658, 515],\n",
       "       [546, 191,  48, 511,  16, 171, 219, 157, 476,  45],\n",
       "       [372, 517,  98, 891, 744,  36, 279, 348, 496, 301],\n",
       "       [180, 606,  98, 699, 992, 115, 190, 252, 980, 927],\n",
       "       [982, 160, 255, 322, 127,  17, 792, 734, 565, 569],\n",
       "       [322, 871, 685, 791, 625, 287, 942, 853, 662, 961],\n",
       "       [638, 154, 489, 385, 985, 784, 103, 928, 392, 810],\n",
       "       [245, 175,  38, 476, 681, 758, 537, 866, 817, 920],\n",
       "       [407, 524, 827, 505, 902, 824,  35, 684,  19, 320],\n",
       "       [775, 511, 399, 653, 971, 882, 470, 142,  91, 353],\n",
       "       [833, 799, 726, 958, 853,  50, 664, 697, 574, 189],\n",
       "       [124, 149, 313, 569, 341, 304, 691, 681, 837, 782],\n",
       "       [ 53, 443, 612, 992, 263,  52, 571, 619,   4, 102],\n",
       "       [195, 773, 876, 991, 883, 349,  46, 866, 822, 935],\n",
       "       [819, 655, 268, 369, 635, 105, 669, 658, 656, 119],\n",
       "       [830, 786, 603,  57, 950, 345, 740, 473, 116, 829],\n",
       "       [790, 126, 392, 907, 640,  57, 633, 512, 750, 801],\n",
       "       [ 95, 637, 117, 559, 600, 487, 236, 884, 896, 271],\n",
       "       [188, 998, 703, 446, 580, 789, 860, 246, 962,  75]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
