{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Embeddings\" data-toc-modified-id=\"Embeddings-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Embeddings</a></span><ul class=\"toc-item\"><li><span><a href=\"#PCA-illustration-of-getting-embeddings\" data-toc-modified-id=\"PCA-illustration-of-getting-embeddings-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>PCA illustration of getting embeddings</a></span></li><li><span><a href=\"#Supervised-example\" data-toc-modified-id=\"Supervised-example-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Supervised example</a></span></li><li><span><a href=\"#Word-embeddings\" data-toc-modified-id=\"Word-embeddings-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Word embeddings</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "*In this context* an embedding is a numerical representation of non-numerical data. The purpose is primarily for 'mathematical convenience' i.e. it enables computations to be made. For example: One Hot encoder encodes a categorical variable with 6 possible values for its value '3' to 0 0 1 0 0 0. In real life this may mean hair color 'blond'. For the complete picture:\n",
    "\n",
    "Color  |  encoding\n",
    ":--- |:--- |\n",
    "Black | 1 0 0 0 0\n",
    "Fair | 0 1 0 0 0\n",
    "Blonde | 0 0 1 0 0\n",
    "Red | 0 0 0 1 0\n",
    "Gray | 0 0 0 0 1\n",
    "None | 0 0 0 0 0\n",
    "\n",
    "In traditional ML one hot encoding worked fine for most cases. However with the appearance of 'Big Data' some problems arose:  \n",
    "    - The number of categories can be huge. E.g. consider the number of titles in the IMDB move database\n",
    "    - The number of observations can be enormous\n",
    "In this 'Big Data' environment One-hot encoding often results in extremely sparse matrices which any, machine or deep, learning algorithm  has problems dealing with.\n",
    "\n",
    "Traditionally PCA would be applied to reduce the number of dimensions. But the disadvantage is that a inverse of the matrix is needed. For enormous data sets this is actually a memory/computational problem: Enter Embeddings/embedding layers.\n",
    "\n",
    "Embedding is in that sense a dimensionality reduction technique to make large categorical data points computationally manageable. There are 2 types of reduction:\n",
    "\n",
    "1. 'Unsupervised' in the sense that it takes the features at face-value \n",
    "PCA could serve as an example from the ML world. PCA tries to minimize the variation \n",
    "2. 'Supervised' in the sense it learns from a 'target', some also called a 'learned' embedding\n",
    "LDA (Linear Discriminant Analysis) is an example. It tries to maximize the separation of known target categories \n",
    "\n",
    "Since Bayes we know that the use of prior information will lead to better predictions. Therefore a 'supervised' embedding is preferred if possible, i.e. when the target is known. In practice a learned embedding if often more meaningful than the 'raw' feature itself.\n",
    "\n",
    "When to use embeddings rather than One_hot?\n",
    "\n",
    "It depends on the number of categories:\n",
    "\n",
    "General rules of thumb:\n",
    "\n",
    "- Under 10 : one hot  \n",
    "- 10-50: use formula embedding_size = min(50, (NumberOfCats+1)/2) \n",
    "- over 50: 50 max.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA illustration of getting embeddings\n",
    "\n",
    "Purely to illustrate what goes on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "import pandas as pd\n",
    "\n",
    "#create categories\n",
    "haircolor = ['black', 'blond', 'fair', 'red', 'grey', 'none', 'marron']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#create data\n",
    "se = []\n",
    "for i in range(100):\n",
    "    se.append(choice(haircolor))\n",
    "df['haircolor'] = se \n",
    "\n",
    "#get the One hot\n",
    "df_ = pd.get_dummies(df[['haircolor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   haircolor\n",
       "41      none\n",
       "93      grey\n",
       "30    marron\n",
       "80       red\n",
       "26     black\n",
       "12      fair\n",
       "96       red\n",
       "89     black\n",
       "63      none\n",
       "9      black"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haircolor_black</th>\n",
       "      <th>haircolor_blond</th>\n",
       "      <th>haircolor_fair</th>\n",
       "      <th>haircolor_grey</th>\n",
       "      <th>haircolor_marron</th>\n",
       "      <th>haircolor_none</th>\n",
       "      <th>haircolor_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    haircolor_black  haircolor_blond  haircolor_fair  haircolor_grey  \\\n",
       "41                0                0               0               0   \n",
       "93                0                0               0               1   \n",
       "30                0                0               0               0   \n",
       "80                0                0               0               0   \n",
       "26                1                0               0               0   \n",
       "12                0                0               1               0   \n",
       "96                0                0               0               0   \n",
       "89                1                0               0               0   \n",
       "63                0                0               0               0   \n",
       "9                 1                0               0               0   \n",
       "\n",
       "    haircolor_marron  haircolor_none  haircolor_red  \n",
       "41                 0               1              0  \n",
       "93                 0               0              0  \n",
       "30                 1               0              0  \n",
       "80                 0               0              1  \n",
       "26                 0               0              0  \n",
       "12                 0               0              0  \n",
       "96                 0               0              1  \n",
       "89                 0               0              0  \n",
       "63                 0               1              0  \n",
       "9                  0               0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.sample(10, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#pca \n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca.fit(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of 7 columns/vectors the feature space as been reduced to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.099904</td>\n",
       "      <td>-0.061422</td>\n",
       "      <td>-0.136065</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.159205</td>\n",
       "      <td>-0.133799</td>\n",
       "      <td>-0.518040</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.391719</td>\n",
       "      <td>0.750140</td>\n",
       "      <td>0.286636</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.263460</td>\n",
       "      <td>-0.623992</td>\n",
       "      <td>0.594397</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.159205</td>\n",
       "      <td>-0.133799</td>\n",
       "      <td>-0.518040</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.072791</td>\n",
       "      <td>-0.039860</td>\n",
       "      <td>-0.078317</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.263460</td>\n",
       "      <td>-0.623992</td>\n",
       "      <td>0.594397</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.159205</td>\n",
       "      <td>-0.133799</td>\n",
       "      <td>-0.518040</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.099904</td>\n",
       "      <td>-0.061422</td>\n",
       "      <td>-0.136065</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.159205</td>\n",
       "      <td>-0.133799</td>\n",
       "      <td>-0.518040</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2 haircolor\n",
       "41 -0.099904 -0.061422 -0.136065      none\n",
       "93 -0.159205 -0.133799 -0.518040      grey\n",
       "30 -0.391719  0.750140  0.286636    marron\n",
       "80 -0.263460 -0.623992  0.594397       red\n",
       "26 -0.159205 -0.133799 -0.518040     black\n",
       "12 -0.072791 -0.039860 -0.078317      fair\n",
       "96 -0.263460 -0.623992  0.594397       red\n",
       "89 -0.159205 -0.133799 -0.518040     black\n",
       "63 -0.099904 -0.061422 -0.136065      none\n",
       "9  -0.159205 -0.133799 -0.518040     black"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df__ = pd.DataFrame(pca.transform(df_))\n",
    "df__['haircolor'] = df['haircolor']\n",
    "df__.sample(10,random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.159205</td>\n",
       "      <td>-0.133799</td>\n",
       "      <td>-0.518040</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.263460</td>\n",
       "      <td>-0.623992</td>\n",
       "      <td>0.594397</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850680</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>0.112261</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.072791</td>\n",
       "      <td>-0.039860</td>\n",
       "      <td>-0.078317</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.099904</td>\n",
       "      <td>-0.061422</td>\n",
       "      <td>-0.136065</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.391719</td>\n",
       "      <td>0.750140</td>\n",
       "      <td>0.286636</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.159205</td>\n",
       "      <td>-0.133799</td>\n",
       "      <td>-0.518040</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2 haircolor\n",
       "0 -0.159205 -0.133799 -0.518040      grey\n",
       "1 -0.263460 -0.623992  0.594397       red\n",
       "2  0.850680  0.098618  0.112261     blond\n",
       "3 -0.072791 -0.039860 -0.078317      fair\n",
       "4 -0.099904 -0.061422 -0.136065      none\n",
       "8 -0.391719  0.750140  0.286636    marron\n",
       "9 -0.159205 -0.133799 -0.518040     black"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df__.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised example\n",
    "\n",
    "**Just illustrating the mechanics** \n",
    "\n",
    "Suppose this s part of marketing survey to see how likely people are to buy suntan lotion.\n",
    "\n",
    "If possible supervised embedding is preferred over unsupervised, but only if it makes sense. I.e. there is a causal relationship between the 2 variables. In this case: hair color(o.k. *natural* hair color) has a causal relationship to the susceptability of sunburn and therefore the likelihood to need and therefore buy suntan lotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create categorical target with 5 values\n",
    "df_['buy_suntan?'] = 'likely'\n",
    "\n",
    "df_.loc[(df_['haircolor_black'] == 1) | (df_['haircolor_marron'] == 1), 'buy_suntan?'] = 'unlikely'\n",
    "df_.loc[(df_['haircolor_grey'] == 1), 'buy_suntan?'] = 'possible'\n",
    "df_.loc[(df_['haircolor_none'] == 1), 'buy_suntan?'] = 'undetermined'\n",
    "df_.loc[(df_['haircolor_red'] == 1), 'buy_suntan?'] = 'very likely'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haircolor_black</th>\n",
       "      <th>haircolor_blond</th>\n",
       "      <th>haircolor_fair</th>\n",
       "      <th>haircolor_grey</th>\n",
       "      <th>haircolor_marron</th>\n",
       "      <th>haircolor_none</th>\n",
       "      <th>haircolor_red</th>\n",
       "      <th>buy_suntan?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>undetermined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unlikely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>very likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unlikely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>very likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unlikely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>undetermined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unlikely</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    haircolor_black  haircolor_blond  haircolor_fair  haircolor_grey  \\\n",
       "41                0                0               0               0   \n",
       "93                0                0               0               1   \n",
       "30                0                0               0               0   \n",
       "80                0                0               0               0   \n",
       "26                1                0               0               0   \n",
       "12                0                0               1               0   \n",
       "96                0                0               0               0   \n",
       "89                1                0               0               0   \n",
       "63                0                0               0               0   \n",
       "9                 1                0               0               0   \n",
       "\n",
       "    haircolor_marron  haircolor_none  haircolor_red   buy_suntan?  \n",
       "41                 0               1              0  undetermined  \n",
       "93                 0               0              0      possible  \n",
       "30                 1               0              0      unlikely  \n",
       "80                 0               0              1   very likely  \n",
       "26                 0               0              0      unlikely  \n",
       "12                 0               0              0        likely  \n",
       "96                 0               0              1   very likely  \n",
       "89                 0               0              0      unlikely  \n",
       "63                 0               1              0  undetermined  \n",
       "9                  0               0              0      unlikely  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.sample(10, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_[['haircolor_black', 'haircolor_blond', 'haircolor_fair',\n",
    "       'haircolor_grey', 'haircolor_marron', 'haircolor_none', 'haircolor_red']]\n",
    "y = df_['buy_suntan?']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embed_1</th>\n",
       "      <th>Embed_2</th>\n",
       "      <th>Embed_3</th>\n",
       "      <th>buy_suntan?</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-8.787144e+15</td>\n",
       "      <td>-1.618485e+16</td>\n",
       "      <td>-1.310974e+14</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Embed_1       Embed_2       Embed_3   buy_suntan? haircolor\n",
       "84  2.968298e+14  2.380468e+15 -2.020174e+15      unlikely     black\n",
       "48  2.968298e+14  2.380468e+15 -2.020174e+15        likely     blond\n",
       "8   2.968298e+14  2.380468e+15 -2.020174e+15      unlikely    marron\n",
       "37  2.968298e+14  2.380468e+15 -2.020174e+15        likely     blond\n",
       "63 -8.787144e+15 -1.618485e+16 -1.310974e+14  undetermined      none\n",
       "62  2.968298e+14  2.380468e+15 -2.020174e+15        likely      fair\n",
       "38  2.968298e+14  2.380468e+15 -2.020174e+15        likely     blond\n",
       "81  2.968298e+14  2.380468e+15 -2.020174e+15      unlikely    marron\n",
       "97  2.968298e+14  2.380468e+15 -2.020174e+15      unlikely     black\n",
       "68  2.968298e+14  2.380468e+15 -2.020174e+15        likely     blond"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=3)\n",
    "ldX = pd.DataFrame(lda.fit(X,y).transform(X), columns=['Embed_1', 'Embed_2', 'Embed_3' ])\n",
    "ldX['buy_suntan?'] = df_['buy_suntan?']\n",
    "ldX['haircolor'] = df['haircolor']\n",
    "ldX.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there are 5 unique embeddings, not 7. This reflects the grouping (only 5) that was coded. E.g. 'blond' and 'fair' have the same embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embed_1</th>\n",
       "      <th>Embed_2</th>\n",
       "      <th>Embed_3</th>\n",
       "      <th>buy_suntan?</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.061810e+16</td>\n",
       "      <td>6.153324e+15</td>\n",
       "      <td>4.870395e+15</td>\n",
       "      <td>possible</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.423744e+16</td>\n",
       "      <td>-3.035051e+15</td>\n",
       "      <td>3.277925e+15</td>\n",
       "      <td>very likely</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>likely</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.787144e+15</td>\n",
       "      <td>-1.618485e+16</td>\n",
       "      <td>-1.310974e+14</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.968298e+14</td>\n",
       "      <td>2.380468e+15</td>\n",
       "      <td>-2.020174e+15</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Embed_1       Embed_2       Embed_3   buy_suntan? haircolor\n",
       "0 -1.061810e+16  6.153324e+15  4.870395e+15      possible      grey\n",
       "1  1.423744e+16 -3.035051e+15  3.277925e+15   very likely       red\n",
       "2  2.968298e+14  2.380468e+15 -2.020174e+15        likely     blond\n",
       "3  2.968298e+14  2.380468e+15 -2.020174e+15        likely      fair\n",
       "4 -8.787144e+15 -1.618485e+16 -1.310974e+14  undetermined      none\n",
       "8  2.968298e+14  2.380468e+15 -2.020174e+15      unlikely    marron\n",
       "9  2.968298e+14  2.380468e+15 -2.020174e+15      unlikely     black"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldX.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "\n",
    "In a sense words can be regarded as nominal categorical variables. Therefore embeddings logic applies here as well. So, in very simplistic terms, Word Embeddings are the texts converted into numbers and there may be different numerical representations of the same text.\n",
    "\n",
    "Different types of Word Embeddings:\n",
    "\n",
    "1. Frequency based Embedding (unsupervised)\n",
    "    1. Count Vectors\n",
    "    - TF-IDF\n",
    "    - Co-Occurrence Matrix\n",
    "\n",
    "2. Prediction based Embedding (supervised)\n",
    "    1. Target variable based  \n",
    "    The embedding is trained on the target y\n",
    "    2. Word2Vec  \n",
    "    The embedding is trained on neighboring words. I.e. the context of a word is considered. The (validated) underlying assumption is that similar words are used in similar contexts and are thus srrounded by similar words.  \n",
    "    2 Main techniques:\n",
    "        1. CBOW  \n",
    "        Continuous Bag Of Words predicts the next word given surrounding words.\n",
    "        - Skip-Gram  \n",
    "        Skip-gram predicts surrounding words given the current word\n",
    "    \n",
    "\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Word2Vec-Training-Models.png\" />\n",
    "https://hackernoon.com/hn-images/1*TTPHUemZjeOjALy9k3KX2w.png\n",
    "<img src=\"https://hackernoon.com/hn-images/1*d47v_FGYKsNT_QRpCNZlfA.png\" />\n",
    "#https://hackernoon.com/hn-images/1*d47v_FGYKsNT_QRpCNZlfA.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1a227f8550>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38, 40], [34, 5], [4, 48], [12, 5], [13], [49], [18, 48], [18, 34], [18, 5], [1, 17, 40, 29]]\n",
      "[[38 40  0  0]\n",
      " [34  5  0  0]\n",
      " [ 4 48  0  0]\n",
      " [12  5  0  0]\n",
      " [13  0  0  0]\n",
      " [49  0  0  0]\n",
      " [18 48  0  0]\n",
      " [18 34  0  0]\n",
      " [18  5  0  0]\n",
      " [ 1 17 40 29]]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'padded_docs2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-f3b7a3c05796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'padded_docs2' is not defined"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# tensorflow.keras.backend.clear_session()\n",
    "np.random.seed(1999)\n",
    "tf.random.set_seed(1999)\n",
    "\n",
    "\n",
    "# from keras.layers.embeddings import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels; i.e. the target\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "\n",
    "# https://stackoverflow.com/questions/54836522/keras-understanding-word-embedding-layer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#this creates the dictionary\n",
    "#IMPORTANT: MUST HAVE ALL DATA - including Test data\n",
    "#IMPORTANT2: This method should be called only once!!!\n",
    "tokenizer.fit_on_texts(docs)\n",
    "\n",
    "#this transforms the texts in to sequences of indices\n",
    "encoded_docs2 = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs2, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38, 40],\n",
       " [34, 5],\n",
       " [4, 48],\n",
       " [12, 5],\n",
       " [13],\n",
       " [49],\n",
       " [18, 48],\n",
       " [18, 34],\n",
       " [18, 5],\n",
       " [1, 17, 40, 29]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 2],\n",
       " [3, 1],\n",
       " [7, 4],\n",
       " [8, 1],\n",
       " [9],\n",
       " [10],\n",
       " [5, 4],\n",
       " [11, 3],\n",
       " [5, 1],\n",
       " [12, 13, 2, 14]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 2],\n",
       " [3, 1],\n",
       " [7, 4],\n",
       " [8, 1],\n",
       " [9],\n",
       " [10],\n",
       " [5, 4],\n",
       " [11, 3],\n",
       " [5, 1],\n",
       " [12, 13, 2, 14]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02814034, -0.02571832, -0.02164843,  0.00919248,  0.04134533,\n",
       "       -0.04751034,  0.03889555,  0.01119905], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_for_word_7 = \n",
    "embeddings[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index = \n",
    "tokenizer.texts_to_sequences([['good']])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-136-bbd657260b76>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-136-bbd657260b76>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    word,index in tokenizer.word_counts.items():\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "word,index in tokenizer.word_counts.items():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "reverse_word_map[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>done</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>work</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>effort</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>poor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>could</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>better</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  1\n",
       "0        well  1\n",
       "1        done  2\n",
       "2        good  2\n",
       "3        work  3\n",
       "4       great  1\n",
       "5      effort  2\n",
       "6        nice  1\n",
       "7   excellent  1\n",
       "8        weak  1\n",
       "9        poor  2\n",
       "10        not  1\n",
       "11      could  1\n",
       "12       have  1\n",
       "13     better  1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tokenizer.word_counts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'better', 2: 'poor', 3: 'work'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_counts_map = dict(map(reversed, tokenizer.word_counts.items()))\n",
    "reverse_counts_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['work', 'done', 'good', 'effort', 'poor', 'well', 'great', 'nice', 'excellent', 'weak', 'not', 'could', 'have', 'better'])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flatten' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-24a9a6bf9a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# for weight and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# for bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# len(model.get_weights())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flatten' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "model.layers[1].params[0]# for weight and \n",
    "model.layers[1].params[1]# for bias\n",
    "\n",
    "# len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 8)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.54075432e-02, -4.03963104e-02,  6.65336847e-03,\n",
       "        -1.14719383e-02,  1.55631565e-02, -3.61280330e-02,\n",
       "         4.50842418e-02,  4.87880148e-02],\n",
       "       [-3.58690023e-02, -1.29931048e-03, -1.16696842e-02,\n",
       "        -2.07555648e-02, -4.53058481e-02,  2.50980593e-02,\n",
       "        -4.68539707e-02,  4.20268811e-02],\n",
       "       [-2.20118407e-02, -1.77681446e-04, -3.03833131e-02,\n",
       "         3.61939110e-02,  3.88005115e-02,  2.01833732e-02,\n",
       "         1.52032860e-02, -3.03264391e-02],\n",
       "       [ 4.78517897e-02, -4.94656563e-02,  4.41753529e-02,\n",
       "         7.77881220e-03, -7.88082927e-03, -3.14554572e-02,\n",
       "         1.34528540e-02, -3.12419068e-02],\n",
       "       [ 1.79635547e-02,  4.58317734e-02, -3.83018740e-02,\n",
       "         2.00751312e-02,  4.88677286e-02, -1.28867626e-02,\n",
       "         2.52642967e-02,  4.88855131e-02],\n",
       "       [ 1.46297254e-02, -2.75191199e-02, -3.34266424e-02,\n",
       "         4.39723767e-02, -1.45487562e-02, -3.46058607e-03,\n",
       "         3.48659866e-02,  4.73571755e-02],\n",
       "       [ 2.81915329e-02,  3.21106799e-02,  1.31844319e-02,\n",
       "        -3.18739563e-02, -4.05411720e-02, -2.30634212e-03,\n",
       "        -4.18144241e-02, -3.68551165e-03],\n",
       "       [ 2.81403400e-02, -2.57183202e-02, -2.16484312e-02,\n",
       "         9.19247791e-03,  4.13453318e-02, -4.75103371e-02,\n",
       "         3.88955511e-02,  1.11990459e-02],\n",
       "       [ 4.29700650e-02,  2.19573714e-02, -2.10694205e-02,\n",
       "        -2.69523747e-02, -4.36961316e-02,  5.91637939e-03,\n",
       "        -1.26193836e-03, -1.96179040e-02],\n",
       "       [ 1.09072551e-02, -5.80348819e-03, -1.32632628e-02,\n",
       "        -2.08572987e-02, -3.90543938e-02,  1.48483366e-03,\n",
       "        -2.71521453e-02,  1.20035037e-02],\n",
       "       [ 2.58939900e-02,  4.04144451e-03,  4.23847511e-03,\n",
       "         1.15691647e-02, -3.32582593e-02, -4.65658307e-02,\n",
       "        -4.62125316e-02, -2.10604817e-03],\n",
       "       [ 1.72170661e-02, -3.09951194e-02, -9.32513550e-03,\n",
       "        -3.94279473e-02, -4.78518605e-02,  6.70834631e-03,\n",
       "        -2.36457586e-03,  4.70198058e-02],\n",
       "       [-1.23099200e-02,  5.55083901e-03,  4.50165980e-02,\n",
       "        -2.93483026e-02,  1.48044899e-03,  4.18191813e-02,\n",
       "         3.00275348e-02, -2.34785806e-02],\n",
       "       [-4.76509333e-02, -4.71942089e-02,  1.75515674e-02,\n",
       "        -2.51952652e-02,  1.24717839e-02, -4.39362191e-02,\n",
       "        -1.53148286e-02, -2.53946315e-02],\n",
       "       [-2.98391934e-02, -2.44816430e-02,  5.55273145e-03,\n",
       "         4.96702082e-02, -4.20347229e-02, -2.63029337e-02,\n",
       "        -1.93789490e-02, -1.52140856e-03],\n",
       "       [-4.17875759e-02, -4.25408259e-02,  1.27441622e-02,\n",
       "        -2.11937316e-02, -5.18111140e-03, -1.96092483e-02,\n",
       "        -1.48353092e-02,  2.49328129e-02],\n",
       "       [ 2.28727795e-02, -3.60679850e-02,  2.51861922e-02,\n",
       "         1.61682256e-02, -1.76418535e-02, -2.91624423e-02,\n",
       "        -3.85300629e-02,  3.30526493e-02],\n",
       "       [-5.52095473e-04, -4.13916111e-02, -4.43653353e-02,\n",
       "        -6.11821562e-03, -4.39674370e-02, -4.20777313e-02,\n",
       "         3.41989510e-02,  3.98895256e-02],\n",
       "       [-1.03205815e-02,  1.29835866e-02, -3.56811881e-02,\n",
       "        -4.19303551e-02, -8.09486955e-03,  4.71881367e-02,\n",
       "         3.25898863e-02,  5.71898371e-03],\n",
       "       [ 3.53681929e-02, -4.00254354e-02, -2.63202917e-02,\n",
       "        -2.58750916e-02,  3.46864350e-02, -4.53450345e-02,\n",
       "         1.46544911e-02, -4.13737893e-02],\n",
       "       [ 5.99443913e-04, -1.45925507e-02, -1.32976174e-02,\n",
       "         2.26581097e-03,  8.83451849e-03,  4.88081686e-02,\n",
       "        -4.61537838e-02,  2.75978558e-02],\n",
       "       [-2.97680739e-02,  8.64468515e-04, -3.00844796e-02,\n",
       "        -1.48239844e-02, -1.47208571e-02, -4.17734981e-02,\n",
       "         4.88599800e-02,  1.60351731e-02],\n",
       "       [-2.53426675e-02,  1.16868988e-02,  1.90869682e-02,\n",
       "         9.28763300e-03, -1.41956583e-02,  4.62357290e-02,\n",
       "        -3.29202414e-03,  1.34240128e-02],\n",
       "       [-1.72881596e-02, -1.72029957e-02,  2.75519826e-02,\n",
       "         3.86980064e-02, -8.54822248e-03, -2.97004338e-02,\n",
       "        -3.99768353e-03, -4.02435437e-02],\n",
       "       [ 1.31070614e-04, -9.19435173e-03,  4.24135216e-02,\n",
       "         1.37270428e-02, -1.15234852e-02,  7.36304373e-03,\n",
       "         3.05379666e-02,  1.66072585e-02],\n",
       "       [-1.15877166e-02,  8.21653754e-03, -1.84311047e-02,\n",
       "        -4.10222411e-02,  4.14596684e-02,  4.51701023e-02,\n",
       "         4.17933501e-02,  1.26550831e-02],\n",
       "       [ 3.33304293e-02,  8.20442289e-03,  1.88861378e-02,\n",
       "        -1.81223750e-02,  7.38300383e-04,  4.39306237e-02,\n",
       "        -2.03660261e-02, -3.08112986e-02],\n",
       "       [ 2.88034715e-02, -4.24076244e-03, -3.18726078e-02,\n",
       "         4.82157134e-02,  2.79917978e-02,  3.40003036e-02,\n",
       "        -7.31755048e-04, -3.93175967e-02],\n",
       "       [-3.37096676e-02, -2.87153963e-02, -4.09442075e-02,\n",
       "        -2.66156346e-03, -1.36437789e-02, -2.19283700e-02,\n",
       "        -3.19436938e-02, -2.94038653e-02],\n",
       "       [-2.73097642e-02, -3.51801887e-02,  1.70291774e-02,\n",
       "        -3.19546945e-02, -3.61550450e-02, -2.44470239e-02,\n",
       "         3.91155221e-02, -4.80644107e-02],\n",
       "       [-2.28548888e-02, -2.90453564e-02, -1.99168921e-02,\n",
       "         3.84183414e-02,  3.05122994e-02, -9.66970995e-03,\n",
       "        -2.43014693e-02,  2.24141218e-02],\n",
       "       [ 2.72687115e-02, -3.50819826e-02, -4.11455147e-02,\n",
       "         2.88711675e-02, -1.61581412e-02, -3.33051682e-02,\n",
       "         1.54086016e-02,  5.05536795e-03],\n",
       "       [ 1.83958896e-02,  4.51535843e-02, -3.71541157e-02,\n",
       "         1.05423555e-02, -1.51384994e-03,  1.16741061e-02,\n",
       "        -4.70750928e-02, -1.70885101e-02],\n",
       "       [ 4.31566872e-02,  3.41550596e-02, -2.41223108e-02,\n",
       "         3.51245292e-02,  3.09159867e-02, -4.57599647e-02,\n",
       "        -1.76278576e-02,  1.35254897e-02],\n",
       "       [ 1.81141384e-02,  1.44342333e-03,  4.20712307e-03,\n",
       "        -3.57489660e-03, -1.17381215e-02,  1.82795413e-02,\n",
       "         4.42419685e-02, -4.51007150e-02],\n",
       "       [-4.01901081e-03, -3.06116696e-02,  9.39661264e-03,\n",
       "        -4.54870611e-03, -5.55914640e-03, -1.08364709e-02,\n",
       "         3.04811075e-03,  4.17564623e-02],\n",
       "       [ 4.55266349e-02, -3.37296501e-02, -4.96469736e-02,\n",
       "         3.40328552e-02, -2.63114925e-02,  4.60160263e-02,\n",
       "        -4.66417670e-02,  3.41315009e-02],\n",
       "       [-4.41832468e-03,  1.85339190e-02, -1.54368281e-02,\n",
       "         3.29645388e-02,  2.50443928e-02,  3.32037099e-02,\n",
       "         5.38409874e-03, -4.54501063e-03],\n",
       "       [-2.67543551e-02,  2.62541808e-02,  4.15630266e-03,\n",
       "        -6.55642897e-03,  1.50758140e-02,  1.10534541e-02,\n",
       "         1.47720240e-02,  1.45584978e-02],\n",
       "       [ 4.52529304e-02,  3.44463438e-03,  2.53463648e-02,\n",
       "         3.16446163e-02,  8.23771954e-03,  3.03318165e-02,\n",
       "        -1.61429159e-02,  2.61483304e-02],\n",
       "       [ 2.00259201e-02, -2.83149611e-02,  2.74991654e-02,\n",
       "        -4.25533429e-02,  4.91521247e-02,  4.26757671e-02,\n",
       "        -3.18416245e-02,  2.80593075e-02],\n",
       "       [ 2.72236951e-02, -3.04628368e-02,  9.09755379e-03,\n",
       "         4.66332696e-02,  4.17321809e-02, -3.36701795e-03,\n",
       "         3.89308855e-03,  3.46284397e-02],\n",
       "       [ 4.27551381e-02,  3.75188924e-02, -1.15926154e-02,\n",
       "        -3.88827808e-02, -4.12931219e-02, -2.10521352e-02,\n",
       "        -3.12946066e-02, -5.74909523e-03],\n",
       "       [-3.16632614e-02, -4.92116697e-02, -3.94385234e-02,\n",
       "        -1.65044144e-03, -3.12126800e-03, -1.90253258e-02,\n",
       "        -4.65788729e-02,  3.43480371e-02],\n",
       "       [ 3.29320505e-03, -1.46086812e-02,  4.00354750e-02,\n",
       "         3.04941274e-02,  4.23978008e-02,  4.70926799e-02,\n",
       "        -3.32882628e-02, -4.11108620e-02],\n",
       "       [ 4.85015400e-02,  3.36597227e-02,  3.29890288e-02,\n",
       "        -4.18093912e-02,  3.18977721e-02, -2.91023254e-02,\n",
       "        -2.01843977e-02,  2.47711204e-02],\n",
       "       [ 3.37710269e-02,  7.48408958e-03,  3.92916836e-02,\n",
       "        -1.96136162e-03, -8.63019377e-03, -6.35982677e-03,\n",
       "        -3.05673722e-02,  3.24418433e-02],\n",
       "       [-3.14059481e-02, -3.23090553e-02,  1.46745555e-02,\n",
       "         4.76990603e-02,  3.68793868e-02, -9.29816812e-03,\n",
       "         1.64613836e-02, -8.44342634e-03],\n",
       "       [ 2.07225196e-02, -3.17962058e-02, -1.80942304e-02,\n",
       "         5.92964888e-03, -9.46149230e-05,  7.86352158e-03,\n",
       "         2.51646303e-02,  1.61924399e-02],\n",
       "       [ 4.29022573e-02,  2.07821019e-02,  4.11763228e-02,\n",
       "        -1.31383054e-02, -4.41824794e-02, -4.77702618e-02,\n",
       "        -4.52952273e-02,  4.04019617e-02]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_to_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-4c319af4b6da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwords_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# now you can use it like this for example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_to_index' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n",
    "\n",
    "# `embeddings` has a shape of (num_vocab, embedding_dim) \n",
    "\n",
    "# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\n",
    "words_embeddings = {w:embeddings[idx] for w, idx in word_to_index.items()}\n",
    "\n",
    "# now you can use it like this for example\n",
    "# print(words_embeddings['love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-67537b94df73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://stackoverflow.com/questions/54836522/keras-understanding-word-embedding-layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/54836522/keras-understanding-word-embedding-layer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#this creates the dictionary\n",
    "#IMPORTANT: MUST HAVE ALL DATA - including Test data\n",
    "#IMPORTANT2: This method should be called only once!!!\n",
    "tokenizer.fit_on_texts(docs)\n",
    "\n",
    "#this transforms the texts in to sequences of indices\n",
    "encoded_docs2 = tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = open('FinKwijt\\glove.6B.100d.txt', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_io.TextIOWrapper' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d8a9ea859afd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglove_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for i in glove_file[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at row 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f715af44761b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nrows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1995\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1996\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 8"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(glove_file, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='FinKwijt\\\\\\\\glove.6B.100d.txt' mode='r' encoding='utf8'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the -0.038194 -0.24487 0.72812 -0.39961 0.0831...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>, -0.10767 0.11053 0.59812 -0.54361 0.67396 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. -0.33979 0.20941 0.46348 -0.64792 -0.38377 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of -0.1529 -0.24279 0.89837 0.16996 0.53516 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to -0.1897 0.050024 0.19084 -0.049184 -0.08973...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  the -0.038194 -0.24487 0.72812 -0.39961 0.0831...\n",
       "1  , -0.10767 0.11053 0.59812 -0.54361 0.67396 0....\n",
       "2  . -0.33979 0.20941 0.46348 -0.64792 -0.38377 0...\n",
       "3  of -0.1529 -0.24279 0.89837 0.16996 0.53516 0....\n",
       "4  to -0.1897 0.050024 0.19084 -0.049184 -0.08973..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/linear-discriminant-analysis-in-python-76b8b17817c2\n",
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = pd.Categorical.from_codes(wine.target, wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[class_0, class_0, class_0, class_0, class_0, ..., class_2, class_2, class_2, class_2, class_2]\n",
       "Length: 178\n",
       "Categories (3, object): [class_0, class_1, class_2]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 3 - 1) = 2 components.\n",
      "  ChangedBehaviorWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "X_lda = lda.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument must be a mpl color, a sequence of mpl colors or a sequence of numbers, not [class_0, class_0, class_0, class_0, class_0, ..., class_2, class_2, class_2, class_2, class_2]\nLength: 178\nCategories (3, object): [class_0, class_1, class_2].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[0;32m   4276\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Then is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4277\u001b[1;33m                 \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4278\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;31m# tuple color.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid RGBA argument: 'class_0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-66734cca10dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rainbow'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0medgecolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2839\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2840\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[1;32m-> 2841\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2842\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4444\u001b[0m             self._parse_scatter_color_args(\n\u001b[0;32m   4445\u001b[0m                 \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4446\u001b[1;33m                 get_next_color_func=self._get_patches_for_fill.get_next_color)\n\u001b[0m\u001b[0;32m   4447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mplotnonfinite\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[0;32m   4296\u001b[0m                         \u001b[1;34m\"'c' argument must be a mpl color, a sequence of mpl \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4297\u001b[0m                         \u001b[1;34m\"colors or a sequence of numbers, not {}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4298\u001b[1;33m                             \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# note: could be long depending on c\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4299\u001b[0m                     )\n\u001b[0;32m   4300\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'c' argument must be a mpl color, a sequence of mpl colors or a sequence of numbers, not [class_0, class_0, class_0, class_0, class_0, ..., class_2, class_2, class_2, class_2, class_2]\nLength: 178\nCategories (3, object): [class_0, class_1, class_2]."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.scatter(\n",
    "    X_lda[:,0],\n",
    "    X_lda[:,1],\n",
    "    c=y,\n",
    "    cmap='rainbow',\n",
    "    alpha=0.7,\n",
    "    edgecolors='b'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9912])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load the Iris flower dataset:\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create an LDA that will reduce the data down to 1 feature\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "# run an LDA and use it to transform the features\n",
    "X_lda = lda.fit(X, y).transform(X)\n",
    "\n",
    "# Print the number of features\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_lda.shape[1])\n",
    "\n",
    "## View the ratio of explained variance\n",
    "lda.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 54\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "# Load libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the data\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Standardize the feature matrix\n",
    "X = StandardScaler().fit_transform(digits.data)\n",
    "y =  digits.target\n",
    "# Create a PCA that will retain 99% of the variance\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "\n",
    "# Conduct PCA\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Show results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 9\n",
      "[0.2891 0.1826 0.1696 0.1167 0.083  0.0657 0.0431 0.0293 0.0208]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(64, 10 - 1) = 9 components.\n",
      "  ChangedBehaviorWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=54)\n",
    "\n",
    "# run an LDA and use it to transform the features\n",
    "X_lda = lda.fit(X, y).transform(X)\n",
    "\n",
    "# Print the number of features\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_lda.shape[1])\n",
    "\n",
    "## View the ratio of explained variance\n",
    "print(lda.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lda.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.drop('buy_suntan?', axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(df_.drop('buy_suntan?', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Python 3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn 0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow 2.0-preview is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(100, 1, input_length=7))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(3))#, activation='sigmoid'))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be\n",
    "# no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "input_array = np.asarray(df_.drop('buy_suntan?', axis=1))#np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "# assert output_array.shape == (32, 10, 64)\n",
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(3, input_shape=input_array.shape[1:])#,\n",
    "#     keras.layers.Dense(3)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('rmsprop', 'mse')\n",
    "output_array_ = model.predict(input_array)\n",
    "# assert output_array.shape == (32, 10, 64)\n",
    "output_array_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>hair_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710024</td>\n",
       "      <td>-0.748557</td>\n",
       "      <td>-0.285666</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.436497</td>\n",
       "      <td>0.294690</td>\n",
       "      <td>0.325131</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.586755</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.191005</td>\n",
       "      <td>0.753687</td>\n",
       "      <td>-0.585121</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.454533</td>\n",
       "      <td>0.574956</td>\n",
       "      <td>-0.742604</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.596687</td>\n",
       "      <td>-0.258554</td>\n",
       "      <td>-0.447850</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.526522</td>\n",
       "      <td>0.332875</td>\n",
       "      <td>0.448169</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2 hair_color\n",
       "0   0.710024 -0.748557 -0.285666      black\n",
       "1  -0.436497  0.294690  0.325131       none\n",
       "2   0.586755 -0.025443  0.317029        red\n",
       "8   0.191005  0.753687 -0.585121       grey\n",
       "9  -0.454533  0.574956 -0.742604     marron\n",
       "11 -0.596687 -0.258554 -0.447850       fair\n",
       "12 -0.526522  0.332875  0.448169      blond"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = pd.DataFrame(output_array_)#.drop_duplicates()\n",
    "dfx['hair_color'] = df['haircolor']\n",
    "dfx.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>haircolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.218256</td>\n",
       "      <td>-0.518452</td>\n",
       "      <td>0.705315</td>\n",
       "      <td>marron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081798</td>\n",
       "      <td>-0.068073</td>\n",
       "      <td>-0.078232</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.130854</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>blond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.154020</td>\n",
       "      <td>-0.195346</td>\n",
       "      <td>-0.468987</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.096952</td>\n",
       "      <td>-0.086958</td>\n",
       "      <td>-0.108315</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.374408</td>\n",
       "      <td>0.792713</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2 haircolor\n",
       "0  -0.218256 -0.518452  0.705315    marron\n",
       "1  -0.081798 -0.068073 -0.078232      fair\n",
       "2   0.868897  0.130854  0.082864     blond\n",
       "3  -0.154020 -0.195346 -0.468987      grey\n",
       "4  -0.154020 -0.195346 -0.468987     black\n",
       "5  -0.096952 -0.086958 -0.108315       red\n",
       "11 -0.374408  0.792713  0.201294      none"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: tf.Tensor(\n[[0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0.]], shape=(2, 7), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-687d5118e10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m model = keras.models.Sequential([\n\u001b[0;32m----> 7\u001b[0;31m     keras.backend.one_hot((100,1), 7)])#,\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#     keras.layers.Dense(3)])#,#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    156\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    157\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: tf.Tensor(\n[[0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0.]], shape=(2, 7), dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.backend.one_hot((100,1), 7)])#,\n",
    "#     keras.layers.Dense(3)])#,#\n",
    "\n",
    "\n",
    "input_array = np.asarray(df)#np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.random.randint(1000, size=(32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(1000, 64, input_length=10))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be\n",
    "# no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143, 608, 200, 123, 186, 325, 463, 348, 770, 659],\n",
       "       [763, 954, 931, 402, 345, 962, 510, 146, 147, 863],\n",
       "       [710, 819, 488, 928, 935, 639, 550, 337, 871, 640],\n",
       "       [778, 987, 952, 472, 945, 150, 414, 989, 297, 610],\n",
       "       [262, 763, 143, 345, 623, 571, 880,   1, 896, 303],\n",
       "       [253, 651, 452,  36, 159,   8, 232,  98, 658, 815],\n",
       "       [207, 130, 403, 151,  53, 119, 672, 919, 627, 586],\n",
       "       [624, 967, 419, 421, 103, 851, 253, 226, 111, 509],\n",
       "       [472,  98, 152, 860, 913, 895, 877, 337, 705, 821],\n",
       "       [162, 719, 956, 680, 995, 160, 579, 800, 397, 276],\n",
       "       [815, 915, 503, 895, 391, 134, 194, 400, 639,  32],\n",
       "       [687, 459, 954, 882, 469, 374,  21, 749, 669,  37],\n",
       "       [229, 364, 562, 437, 775, 282,  26, 225, 276, 797],\n",
       "       [608, 283, 878, 959, 480, 452, 828, 815, 658, 515],\n",
       "       [546, 191,  48, 511,  16, 171, 219, 157, 476,  45],\n",
       "       [372, 517,  98, 891, 744,  36, 279, 348, 496, 301],\n",
       "       [180, 606,  98, 699, 992, 115, 190, 252, 980, 927],\n",
       "       [982, 160, 255, 322, 127,  17, 792, 734, 565, 569],\n",
       "       [322, 871, 685, 791, 625, 287, 942, 853, 662, 961],\n",
       "       [638, 154, 489, 385, 985, 784, 103, 928, 392, 810],\n",
       "       [245, 175,  38, 476, 681, 758, 537, 866, 817, 920],\n",
       "       [407, 524, 827, 505, 902, 824,  35, 684,  19, 320],\n",
       "       [775, 511, 399, 653, 971, 882, 470, 142,  91, 353],\n",
       "       [833, 799, 726, 958, 853,  50, 664, 697, 574, 189],\n",
       "       [124, 149, 313, 569, 341, 304, 691, 681, 837, 782],\n",
       "       [ 53, 443, 612, 992, 263,  52, 571, 619,   4, 102],\n",
       "       [195, 773, 876, 991, 883, 349,  46, 866, 822, 935],\n",
       "       [819, 655, 268, 369, 635, 105, 669, 658, 656, 119],\n",
       "       [830, 786, 603,  57, 950, 345, 740, 473, 116, 829],\n",
       "       [790, 126, 392, 907, 640,  57, 633, 512, 750, 801],\n",
       "       [ 95, 637, 117, 559, 600, 487, 236, 884, 896, 271],\n",
       "       [188, 998, 703, 446, 580, 789, 860, 246, 962,  75]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
